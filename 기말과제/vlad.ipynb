{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLAD를 통해 디스크립터 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flower', 'mouse', 'umbrella']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def compute_vlad(image, des, labels, centers):\n",
    "    # SIFT 특징점 검출과 특징 디스크립터 계산을 한 번에 수행\n",
    "    sift = cv2.SIFT_create(edgeThreshold=80)\n",
    "    _, des = sift.detectAndCompute(image, None)\n",
    "    \n",
    "    if des is None: \n",
    "        return None\n",
    "    \n",
    "    # VLAD 벡터 초기화\n",
    "    vlad = np.zeros((centers.shape[0], des.shape[1]), dtype=np.float32)\n",
    "    \n",
    "    # 누적합\n",
    "    for i in range(des.shape[0]):\n",
    "        vlad[labels[i]] += des[i] - centers[labels[i]]\n",
    "        \n",
    "    # VLAD 벡터 정규화\n",
    "    vlad = cv2.normalize(vlad, None).flatten()\n",
    "    vlad /= np.linalg.norm(vlad)\n",
    "    return vlad\n",
    "\n",
    "def similar_images(query_image, category_images, k):\n",
    "    sift = cv2.SIFT_create(edgeThreshold=80)\n",
    "    \n",
    "    # 특징점 및 디스크립터 계산\n",
    "    query_image = cv2.resize(query_image, (300, 300))\n",
    "    _, query_des = sift.detectAndCompute(query_image, None) # 이미지 특징점 검출과 특징 디스크립터 계산을 한 번에 수행\n",
    "    if query_des is None:\n",
    "        return None\n",
    "\n",
    "    # data 이미지에 대해 클러스터링 수행\n",
    "    category_des = []\n",
    "    for category, images in category_images.items():\n",
    "        for image in images:\n",
    "            _, des = sift.detectAndCompute(image, None)\n",
    "            if des is not None:\n",
    "                category_des.extend(des)\n",
    "\n",
    "    category_des = np.array(category_des)\n",
    "\n",
    "    # k-means clustering\n",
    "    num_clusters = k\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, labels, centers = cv2.kmeans(category_des, num_clusters, None, criteria, 5, flags)\n",
    "\n",
    "    # 입력 이미지 VLAD 연산\n",
    "    query_vlad = compute_vlad(query_image, query_des, labels, centers)\n",
    "    if query_vlad is None:\n",
    "        return None\n",
    "\n",
    "    similarity_scores = {}\n",
    "    for category, images in category_images.items():\n",
    "        category_vlads = []\n",
    "        for image in images:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (300, 300))\n",
    "            _, des = sift.detectAndCompute(image, None)\n",
    "            if des is not None:\n",
    "                category_vlads.append(compute_vlad(image, des, labels, centers))\n",
    "\n",
    "        category_vlads = np.array(category_vlads)\n",
    "\n",
    "        # distances 계산\n",
    "        distances = np.linalg.norm(query_vlad - category_vlads, axis=1)\n",
    "        similarity_scores[category] = np.mean(distances)\n",
    "\n",
    "    # 유사성을 기준으로 정렬, 유사도가 큰 것 부터 내림차순 정렬\n",
    "    sorted_categories = sorted(similarity_scores, key=similarity_scores.get)\n",
    "    top_categories = sorted_categories[:k]\n",
    "\n",
    "    return top_categories\n",
    "\n",
    "path = 'c:/data/temp/'\n",
    "\n",
    "# 입력 이미지\n",
    "query_image_path =  path + 'flower6.jpg'\n",
    "# query_image_path =  path + 'mouse6.jpg'\n",
    "# query_image_path =  path + 'umb6.jpg'\n",
    "\n",
    "# 분류할 카테고리와 해당 카테고리의 이미지들을 딕셔너리로 정의\n",
    "categories = {\n",
    "    'mouse': [cv2.imread(path + 'mouse1.jpg'), cv2.imread(path + 'mouse2.jpg'), cv2.imread(path + 'mouse3.jpg'), \n",
    "              cv2.imread(path + 'mouse4.jpg'), cv2.imread(path + 'mouse5.jpg')],\n",
    "    'flower': [cv2.imread(path + 'flower1.jpg'), cv2.imread(path + 'flower2.jpg'), cv2.imread(path + 'flower3.jpg'), \n",
    "               cv2.imread(path + 'flower4.jpg'), cv2.imread(path + 'flower5.jpg')],\n",
    "    'umbrella': [cv2.imread(path + 'umb1.jpg'), cv2.imread(path + 'umb2.jpg'), cv2.imread(path + 'umb3.jpg'),\n",
    "                 cv2.imread(path + 'umb4.jpg'), cv2.imread(path + 'umb5.jpg')]\n",
    "}\n",
    "\n",
    "# 입력 이미지 불러오기\n",
    "query_image = cv2.imread(query_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 유사도 검사\n",
    "k = 1 # 출력할 카테고리 수\n",
    "top_categories = similar_images(query_image, categories, k) # 실행\n",
    "\n",
    "# 유사한 카테고리를 유사도가 높은 순으로 출력\n",
    "print(top_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "imgSize = (300, 300)\n",
    "\n",
    "def siftDes(src):\n",
    "    gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    siftF = cv2.SIFT_create()\n",
    "    kp = siftF.detect(gray)\n",
    "    kp = sorted(kp, key=lambda f: f.response, reverse=True)\n",
    "    return kp, siftF.compute(gray, kp)[1]\n",
    "\n",
    "def compute_vlad(descriptors, k):\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.1)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, labels, centers = cv2.kmeans(descriptors, k, None, criteria, 10, flags)\n",
    "    vlad_vector = np.zeros((k, descriptors.shape[1]), dtype=np.float32)\n",
    "    for i in range(descriptors.shape[0]):\n",
    "        vlad_vector[labels[i]] += descriptors[i] - centers[labels[i]]\n",
    "    vlad_vector = cv2.normalize(vlad_vector, vlad_vector, norm_type=cv2.NORM_L2)\n",
    "    return vlad_vector.flatten()\n",
    "\n",
    "def detect_similar_images(query_image_path, data_image_paths, num_results=5):\n",
    "    # Load the query image\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    query_image = cv2.resize(query_image, imgSize)\n",
    "    \n",
    "    # Create the feature detector (SIFT)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors for the query image\n",
    "    query_keypoints, query_descriptors = siftDes(query_image)\n",
    "\n",
    "    # Group data images by category\n",
    "    data_categories = {\n",
    "        'mouse': [],\n",
    "        'flower': [],\n",
    "        'umbrella': []\n",
    "    }\n",
    "\n",
    "    for image_path in data_image_paths:\n",
    "        if 'mouse' in image_path:\n",
    "            data_categories['mouse'].append(image_path)\n",
    "        elif 'flower' in image_path:\n",
    "            data_categories['flower'].append(image_path)\n",
    "        elif 'umb' in image_path:\n",
    "            data_categories['umbrella'].append(image_path)\n",
    "\n",
    "    # Perform VLAD computation for each category\n",
    "    vlad_vectors = {}\n",
    "    for category, image_paths in data_categories.items():\n",
    "        descriptors = []\n",
    "        for image_path in image_paths:\n",
    "            image = cv2.imread(image_path)\n",
    "            _, desc = siftDes(image)\n",
    "            descriptors.append(desc)\n",
    "        descriptors = np.concatenate(descriptors)\n",
    "        vlad_vector = compute_vlad(descriptors, k=3)\n",
    "        vlad_vectors[category] = vlad_vector\n",
    "\n",
    "    # Compute the VLAD vector for the query image\n",
    "    query_vlad = compute_vlad(query_descriptors, k=3)\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = {}\n",
    "    for category, vlad_vector in vlad_vectors.items():\n",
    "        distance = np.linalg.norm(query_vlad - vlad_vector)\n",
    "        similarity_scores[category] = distance\n",
    "\n",
    "    # Sort the categories based on similarity scores (lower score indicates higher similarity)\n",
    "    sorted_categories = sorted(similarity_scores, key=similarity_scores.get)\n",
    "\n",
    "    # Retrieve the top similar images from the most similar category\n",
    "    similar_images = []\n",
    "    for category in sorted_categories:\n",
    "        images = data_categories[category][:num_results]\n",
    "        for image_path in images:\n",
    "            image = cv2.imread(image_path)\n",
    "            similar_images.append(image)\n",
    "\n",
    "    return similar_images\n",
    "\n",
    "path = 'c:/data/temp/'\n",
    "query_image_path = path + 'mouse (6).jpg'\n",
    "data_image_paths = [path + 'flower1.jpg', path + 'flower2.jpg', path + 'flower3.jpg', path + 'flower4.jpg', path + 'flower5.jpg',\n",
    "                    path + 'umb1.jpg', path + 'umb2.jpg', path + 'umb3.jpg', path + 'umb4.jpg', path + 'umb5.jpg',\n",
    "                    path + 'mouse (1).jpg', path + 'mouse (2).jpg', path + 'mouse (3).jpg', path + 'mouse (4).jpg']\n",
    "\n",
    "# Detect similar images\n",
    "similar_images = detect_similar_images(query_image_path, data_image_paths)\n",
    "\n",
    "# Display the similar images\n",
    "for i in range(len(similar_images)):\n",
    "    image = cv2.resize(similar_images[i], (300, 300))\n",
    "    cv2.imshow('Similar Image ' + str(i+1), image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
